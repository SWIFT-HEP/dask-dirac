{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Graph\n",
    "Notebook to manipulate a dask graph at the client stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Edit submit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Create a Dask client\n",
    "client = Client()\n",
    "\n",
    "original_submit = client.submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_submit(*args, **kwargs):\n",
    "    print(\"Entered Submit\")\n",
    "    print(\"Party if it works\")\n",
    "    return original_submit(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.submit = modified_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered Submit\n",
      "Party if it works\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>Future: neg</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">pending</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> NoneType,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> neg-6509467a9c66ce2389f8f71ccfe663b3"
      ],
      "text/plain": [
       "<Future: pending, key: neg-6509467a9c66ce2389f8f71ccfe663b3>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg(x):\n",
    "    return -x\n",
    "\n",
    "\n",
    "client.submit(neg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 19:37:55,387 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:16903' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'neg-6509467a9c66ce2389f8f71ccfe663b3'} (stimulus_id='handle-worker-cleanup-1718822275.387008')\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Edit collections_to_dsk method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Save original collections_to_dsk method\n",
    "original_collections_to_dsk = client.collections_to_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections_to_dsk method has been replaced\n"
     ]
    }
   ],
   "source": [
    "def modified_collections_to_dsk(collections, *args, **kwargs):\n",
    "    c = datetime.now()\n",
    "    print(\"Inside myFunc. Time = \" + c.strftime(\"%H:%M:%S\"))\n",
    "    print(\"Dask Graph Tasks\")\n",
    "    for collection in collections:\n",
    "        print(f\"Task Name: {collection.name}\")\n",
    "    print(\"-----------------\\n\")\n",
    "\n",
    "    return original_collections_to_dsk(collections, *args, **kwargs)\n",
    "\n",
    "\n",
    "client.collections_to_dsk = modified_collections_to_dsk\n",
    "print(\"collections_to_dsk method has been replaced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.ones((1000, 1000), chunks=(100, 100))\n",
    "y = x + 1\n",
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside myFunc. Time = 19:38:18\n",
      "Dask Graph Tasks\n",
      "Task Name: mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = client.compute(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 19:38:31,549 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:21019' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'finalize-3daf4f11543bcdbd0d181b8d6c929af3'} (stimulus_id='handle-worker-cleanup-1718822311.5493789')\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Do some basic caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.1: Keep client running\n",
    "This will cause an issue as the client still has memory of the task and hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.highlevelgraph import HighLevelGraph\n",
    "from datetime import datetime\n",
    "\n",
    "client = Client()\n",
    "\n",
    "original_collections_to_dsk = client.collections_to_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_functions = []\n",
    "\n",
    "\n",
    "def add_to_three(number):\n",
    "    return number + 3\n",
    "\n",
    "\n",
    "def modified_collections_to_dsk(collections, *args, **kwargs):\n",
    "    c = datetime.now()\n",
    "    print(\"Inside myFunc. Time = \" + c.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print(\"Functions already processed\")\n",
    "    global existing_functions\n",
    "    for funcs in existing_functions:\n",
    "        print(f\"{funcs}\")\n",
    "\n",
    "    print(\"Dask Graph Tasks\")\n",
    "    for collection in collections:\n",
    "        print(f\"Task Name: {collection.name}\")\n",
    "        print(\"Dask Graph\")\n",
    "        print(collection.dask)\n",
    "        if collection.name not in existing_functions:\n",
    "            print(f\"Adding {collection.name} to existing_functions\")\n",
    "            existing_functions.append(collection.name)\n",
    "        else:\n",
    "            print(f\"{collection.name} has already been processed\")\n",
    "            # TODO: Continue playing around with the dask graph so return is not a string\n",
    "            # TODO: Use collection hash rather than collection name\n",
    "            layers = {\n",
    "                f\"add_to_three-{(collection.name)}\": {\n",
    "                    (f\"add_to_three-{(collection.name)}\", 0): (add_to_three, 20)\n",
    "                }\n",
    "            }\n",
    "            dependencies = {f\"add_to_three-{(collection.name)}\": set()}\n",
    "            graph = HighLevelGraph(layers, dependencies)\n",
    "            collection.dask = graph\n",
    "            print(\"New Dask Graph\")\n",
    "            print(collection.dask)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    return original_collections_to_dsk(collections, *args, **kwargs)\n",
    "\n",
    "\n",
    "client.collections_to_dsk = modified_collections_to_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.ones((1000, 1000), chunks=(100, 100))\n",
    "y = x + 1\n",
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside myFunc. Time = 19:40:19\n",
      "Functions already processed\n",
      "Dask Graph Tasks\n",
      "Task Name: mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "Dask Graph\n",
      "HighLevelGraph with 7 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7f95fa07f3a0>\n",
      " 0. ones_like-c53a97836143a00162e3470fef213e1e\n",
      " 1. add-098526cf93d1ac0d3a8744f59d0814fb\n",
      " 2. mean_chunk-4e5168d025885dfbdfd76df3f8083cda\n",
      " 3. mean_combine-partial-0832826c732652f3243668d740a0d5f3\n",
      " 4. mean_combine-partial-f33215f12dcb169d48ded3405ae5b4a2\n",
      " 5. mean_combine-partial-f380b3499d120118c907e62d760350cc\n",
      " 6. mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "\n",
      "Adding mean_agg-aggregate-c50263a0ad47c330577b3058195ad928 to existing_functions\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "result = client.compute(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: finalize</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">finished</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> numpy.float64,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> finalize-3daf4f11543bcdbd0d181b8d6c929af3"
      ],
      "text/plain": [
       "<Future: finished, type: numpy.float64, key: finalize-3daf4f11543bcdbd0d181b8d6c929af3>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside myFunc. Time = 19:40:23\n",
      "Functions already processed\n",
      "mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "Dask Graph Tasks\n",
      "Task Name: mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "Dask Graph\n",
      "HighLevelGraph with 7 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7f95fa07f3a0>\n",
      " 0. ones_like-c53a97836143a00162e3470fef213e1e\n",
      " 1. add-098526cf93d1ac0d3a8744f59d0814fb\n",
      " 2. mean_chunk-4e5168d025885dfbdfd76df3f8083cda\n",
      " 3. mean_combine-partial-0832826c732652f3243668d740a0d5f3\n",
      " 4. mean_combine-partial-f33215f12dcb169d48ded3405ae5b4a2\n",
      " 5. mean_combine-partial-f380b3499d120118c907e62d760350cc\n",
      " 6. mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "\n",
      "mean_agg-aggregate-c50263a0ad47c330577b3058195ad928 has already been processed\n",
      "New Dask Graph\n",
      "HighLevelGraph with 1 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7f95f8773c70>\n",
      " 0. add_to_three-mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 19:40:23,945 - distributed.scheduler - WARNING - Detected different `run_spec` for key 'finalize-3daf4f11543bcdbd0d181b8d6c929af3' between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: memory\n",
      "old run_spec: (<function finalize at 0x7f96080ec280>, ([('mean_agg-aggregate-c50263a0ad47c330577b3058195ad928',)],), {})\n",
      "new run_spec: (<function finalize at 0x7f96080ec280>, ([('mean_agg-aggregate-c50263a0ad47c330577b3058195ad928',)],), {})\n",
      "old token: ('tuple', [('ae65af090ad79ae2e434bc4c7eb750244a1a40bb', []), ('tuple', [('list', [('tuple', ['mean_agg-aggregate-c50263a0ad47c330577b3058195ad928'])])]), ('dict', [])])\n",
      "new token: ('tuple', [('ae65af090ad79ae2e434bc4c7eb750244a1a40bb', []), ('tuple', [('list', [('tuple', ['mean_agg-aggregate-c50263a0ad47c330577b3058195ad928'])])]), ('dict', [])])\n",
      "old dependencies: {('mean_agg-aggregate-c50263a0ad47c330577b3058195ad928',)}\n",
      "new dependencies: set()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute a second time\n",
    "result = client.compute(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 19:40:46,904 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:13361' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'finalize-3daf4f11543bcdbd0d181b8d6c929af3'} (stimulus_id='handle-worker-cleanup-1718822446.9042947')\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.2: Edit HighLevelGraph in a new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.highlevelgraph import HighLevelGraph\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "original_collections_to_dsk = client.collections_to_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_functions = [\"mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\"]\n",
    "\n",
    "\n",
    "def modified_collections_to_dsk(collections, *args, **kwargs):\n",
    "    c = datetime.now()\n",
    "    print(\"Inside myFunc. Time = \" + c.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print(\"Functions already processed\")\n",
    "    global existing_functions\n",
    "    for funcs in existing_functions:\n",
    "        print(f\"{funcs}\")\n",
    "\n",
    "    print(\"Dask Graph Tasks\")\n",
    "    for collection in collections:\n",
    "        print(f\"Task Name: {collection.name}\")\n",
    "        print(\"Dask Graph\")\n",
    "        print(collection.dask)\n",
    "        if collection.name not in existing_functions:\n",
    "            print(f\"Adding {collection.name} to existing_functions\")\n",
    "            existing_functions.append(collection.name)\n",
    "        else:\n",
    "            print(f\"{collection.name} has already been processed\")\n",
    "            # TODO: Continue playing around with the dask graph so return is not a string\n",
    "            # TODO: Use collection hash rather than collection name\n",
    "            layers = {\n",
    "                f\"add_to_three-{(collection.name)}\": {\n",
    "                    (f\"add_to_three-{(collection.name)}\", 0): (add_to_three, 20)\n",
    "                }\n",
    "            }\n",
    "            dependencies = {f\"add_to_three-{(collection.name)}\": set()}\n",
    "            graph = HighLevelGraph(layers, dependencies)\n",
    "            collection.dask = graph\n",
    "            # layers = {f\"add_to_thre11e-{(collection.name)}\": {(f\"add_to_three-{(collection.name)}\", 0): (add_to_three, 20)}}\n",
    "            # layers = {f\"add_to_thre11e-{(collection.name)}\": (add_to_three, 20)}\n",
    "            # dependencies = {f\"add_to_three-{(collection.name)}\": set()}\n",
    "            # graph = HighLevelGraph(layers, dependencies)\n",
    "            # collection.dask = graph\n",
    "            print(\"New Dask Graph\")\n",
    "            print(collection.dask)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    return original_collections_to_dsk(collections, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections_to_dsk = modified_collections_to_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_three(number):\n",
    "    return number + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside myFunc. Time = 19:43:16\n",
      "Functions already processed\n",
      "mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "Dask Graph Tasks\n",
      "Task Name: mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "Dask Graph\n",
      "HighLevelGraph with 7 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7f9608d4ba90>\n",
      " 0. ones_like-c53a97836143a00162e3470fef213e1e\n",
      " 1. add-098526cf93d1ac0d3a8744f59d0814fb\n",
      " 2. mean_chunk-4e5168d025885dfbdfd76df3f8083cda\n",
      " 3. mean_combine-partial-0832826c732652f3243668d740a0d5f3\n",
      " 4. mean_combine-partial-f33215f12dcb169d48ded3405ae5b4a2\n",
      " 5. mean_combine-partial-f380b3499d120118c907e62d760350cc\n",
      " 6. mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "\n",
      "mean_agg-aggregate-c50263a0ad47c330577b3058195ad928 has already been processed\n",
      "New Dask Graph\n",
      "HighLevelGraph with 1 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7f95fa07fa00>\n",
      " 0. add_to_three-mean_agg-aggregate-c50263a0ad47c330577b3058195ad928\n",
      "\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "x = da.ones((1000, 1000), chunks=(100, 100))\n",
    "y = x + 1\n",
    "z = y.mean()\n",
    "result = client.compute(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: finalize</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">finished</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> str,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> finalize-3daf4f11543bcdbd0d181b8d6c929af3"
      ],
      "text/plain": [
       "<Future: finished, type: str, key: finalize-3daf4f11543bcdbd0d181b8d6c929af3>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean_agg-aggregate-c50263a0ad47c330577b3058195ad928'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.3: Try with blockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/swift-hep/envs/dask_dirac/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 16985 instead\n",
      "  warnings.warn(\n",
      "2024-06-24 22:40:59,285 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:16327' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'finalize-99beb22034172632fdd161427fa0c2cc'} (stimulus_id='handle-worker-cleanup-1719265259.285501')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "[20 35 54]\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from dask.highlevelgraph import HighLevelGraph\n",
    "from datetime import datetime\n",
    "from dask.array.core import Array\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define some simple functions to use in the graph\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "\n",
    "# Create a Dask array from the HighLevelGraph\n",
    "# Note: We need to specify the shape and chunks of the resulting array\n",
    "dask_array = da.blockwise(\n",
    "    lambda x, y: multiply(add(x, y), y),\n",
    "    \"i\",\n",
    "    np.array([1, 2, 3]),\n",
    "    \"i\",\n",
    "    np.array([4, 5, 6]),\n",
    "    \"i\",\n",
    "    dtype=np.int64,\n",
    ")\n",
    "\n",
    "# Use client.compute to compute the result\n",
    "future = client.compute(dask_array)\n",
    "result = future.result()\n",
    "\n",
    "client.shutdown()\n",
    "\n",
    "print(\"------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/swift-hep/envs/dask_dirac/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 25436 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside myFunc. Time = 22:41:44\n",
      "Functions already processed\n",
      "Dask Graph Tasks\n",
      "Task Name: lambda-bd96b5ee7bd8b34908deaa71441f1d4a\n",
      "Dask Graph\n",
      "HighLevelGraph with 3 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7fae2833ff10>\n",
      " 0. array-93899268a02d75f85755ccb59b755ad1\n",
      " 1. array-08b8023b2db8bebf73813d166e3f6b63\n",
      " 2. lambda-bd96b5ee7bd8b34908deaa71441f1d4a\n",
      "\n",
      "-----------------\n",
      "Edditing Dask Graph\n",
      "New Dask Graph\n",
      "HighLevelGraph with 3 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x7fae481a7190>\n",
      " 0. array-71a7394e5f14de7dc72bb0b1b251ce84\n",
      " 1. array-e3622cdb87acdb3eed57eec6c2ef9fb7\n",
      " 2. lambda-19e9145bca12a9b712321a40e73e64bd\n",
      "\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:41:45,478 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:21393' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'finalize-a78071afc5b678a3bf5936b8a138ce3f'} (stimulus_id='handle-worker-cleanup-1719265305.478143')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "[104 135 170]\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from dask.highlevelgraph import HighLevelGraph\n",
    "from datetime import datetime\n",
    "from dask.array.core import Array\n",
    "\n",
    "\n",
    "def modified_collections_to_dsk(collections, *args, **kwargs):\n",
    "    c = datetime.now()\n",
    "    print(\"Inside myFunc. Time = \" + c.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print(\"Functions already processed\")\n",
    "\n",
    "    print(\"Dask Graph Tasks\")\n",
    "    for collection in collections:\n",
    "        print(f\"Task Name: {collection.name}\")\n",
    "        print(\"Dask Graph\")\n",
    "        print(collection.dask)\n",
    "        print(\"-----------------\")\n",
    "        print(\"Edditing Dask Graph\")\n",
    "        dask_array = da.blockwise(\n",
    "            lambda x, y: multiply(add(x, y), y),\n",
    "            \"i\",\n",
    "            np.array([5, 6, 7]),\n",
    "            \"i\",\n",
    "            np.array([8, 9, 10]),\n",
    "            \"i\",\n",
    "            dtype=np.int64,\n",
    "        )\n",
    "        collection.dask = dask_array.dask\n",
    "        collection.__dask_keys__ = dask_array.__dask_keys__\n",
    "\n",
    "        print(\"New Dask Graph\")\n",
    "        print(collection.dask)\n",
    "\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    return original_collections_to_dsk(collections, *args, **kwargs)\n",
    "\n",
    "\n",
    "client = Client()\n",
    "\n",
    "original_collections_to_dsk = client.collections_to_dsk\n",
    "\n",
    "client.collections_to_dsk = modified_collections_to_dsk\n",
    "\n",
    "# Define some simple functions to use in the graph\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "\n",
    "# Create a Dask array from the HighLevelGraph\n",
    "# Note: We need to specify the shape and chunks of the resulting array\n",
    "dask_array = da.blockwise(\n",
    "    lambda x, y: multiply(add(x, y), y),\n",
    "    \"i\",\n",
    "    np.array([1, 2, 3]),\n",
    "    \"i\",\n",
    "    np.array([4, 5, 6]),\n",
    "    \"i\",\n",
    "    dtype=np.int64,\n",
    ")\n",
    "\n",
    "# Use client.compute to compute the result\n",
    "future = client.compute(dask_array)\n",
    "result = future.result()\n",
    "\n",
    "client.shutdown()\n",
    "\n",
    "print(\"------------\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
