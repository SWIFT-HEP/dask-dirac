{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIFT-HEP / GridPP Workshop - April 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "The Dirac Client is introduced here.\n",
    "Functionally it works the same as the dask.distributed.Client, but allows for persistent caching.\n",
    "\n",
    "The following cache locations are supported:\n",
    "- `local`: to set the directory use `file:///path/to/cache`\n",
    "\n",
    "Caching options in the works;\n",
    "- `rucio`: to set the directory use `rucio:///path/to/cache`\n",
    "- `dirac`: to set the directory use `dirac:///path/to/cache`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_dirac import DiracClient, DiracCluster\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task structure has changed in newer versions, so for this using 2024.5.0\n",
    "import dask\n",
    "dask.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = DiracClient(cluster, \n",
    "                     cache_location=\"file:///tmp/dask-cache_05022025\")\n",
    "#client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the cache location and show what files are there\n",
    "print(client.cache_location)\n",
    "!ls {client.cache_location[7:]} # remove file:// at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dask DataFrame directly\n",
    "dask_array = da.ones((1e4, 1), chunks=(1)) + 20231\n",
    "dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.compute(dask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the cache location and show what files are there\n",
    "print(client.cache_location)\n",
    "!ls {client.cache_location[7:]} # remove file:// at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU vs CPU\n",
    "\n",
    "This is an LUX-ZEPLIN analysis which builds a model of multi-scatter-single-ionisation (MSSI) events from simulated events.\n",
    "This simulated events are from detector components. \n",
    "In this analysis, the simulations (ROOT files) are read using `uproot`, and then events are looped over, selecting MSSI events.\n",
    "The simulated events here have already gone through a pre-processing so only events classified as single-scatter events are considered.\n",
    "\n",
    "A more detailed step-by-step description of the analysis is as follows:\n",
    "1. Simulations of detector components are stored as ROOT files.\n",
    "2. These files are read using `uproot` into `awkward` arrays.\n",
    "3. A selection is applied to the data to select MSSI events.\n",
    "4. A normalization is applied to get the expected rate of these events.\n",
    "5. Something about building the model.\n",
    "\n",
    "\n",
    "In addition to the above, this analysis also highlights function decorations with numba for CPU and GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from dask.distributed import LocalCluster, Client, progress\n",
    "import glob\n",
    "import pandas as pd\n",
    "import uproot as up\n",
    "import numba\n",
    "import dask\n",
    "from numba import cuda\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FV: Wall Radius cut\n",
    "\"\"\"\n",
    "@numba.njit\n",
    "def fv_wall_contour(dt):\n",
    "    c = [-4.44147071e-14, 1.43684777e-10, -1.82739476e-07, 1.02160174e-04, -2.31617857e-02, -2.05932471e+00]\n",
    "    wall_r2 = c[0]*dt**5 + c[1]*dt**4 + c[2]*dt**3 + c[3]*dt**2 + c[4]*dt + c[5]\n",
    "    return wall_r2\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def fv_wall_contour_cuda(dt):\n",
    "    return -4.44147071e-14 * math.pow(dt, 5) \\\n",
    "            + 1.43684777e-10 * math.pow(dt, 4) \\\n",
    "            -1.82739476e-07 * math.pow(dt, 3) \\\n",
    "                + 1.02160174e-04 * math.pow(dt, 2) \\\n",
    "                    -2.31617857e-02 * dt \\\n",
    "                        -2.05932471e+00\n",
    "\n",
    "\"\"\"\n",
    "FV: Radial position\n",
    "\"\"\"\n",
    "n_phi_slices = 12\n",
    "phi_slices = np.linspace(-np.pi, np.pi, n_phi_slices + 1) + np.pi/4\n",
    "phi_slices[phi_slices > np.pi] -= 2*np.pi\n",
    "\n",
    "@numba.njit\n",
    "def calc_dR_phi(x, y, dt):\n",
    "\n",
    "    # Calculate event radii and angles, then mask them according to each slice\n",
    "    R = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "\n",
    "    dR_phi = 0.0\n",
    "    # Process each phi slice\n",
    "    for slice in range(n_phi_slices):\n",
    "        phi_min, phi_max = phi_slices[slice], phi_slices[slice + 1]\n",
    "        if (phi >= phi_min) & (phi < phi_max):\n",
    "            dR_phi = R - perform_poly(dt, slice)\n",
    "\n",
    "    return dR_phi\n",
    "\n",
    "@cuda.jit\n",
    "def calc_dR_phi_cuda(x, y, dt):\n",
    "    R = math.sqrt(x ** 2 + y ** 2)\n",
    "    phi = math.atan2(y, x)\n",
    "\n",
    "    n_phi_slices = 12\n",
    "    # Now define array on device\n",
    "    phi_slices = cuda.local.array(13, dtype=numba.float32) \n",
    "    phi_slices[0] = -2.35619449\n",
    "    phi_slices[1] = -1.83259571\n",
    "    phi_slices[2] = -1.30899694\n",
    "    phi_slices[3] = -0.78539816\n",
    "    phi_slices[4] = -0.26179939\n",
    "    phi_slices[5] = 0.26179939\n",
    "    phi_slices[6] = 0.78539816\n",
    "    phi_slices[7] = 1.30899694\n",
    "    phi_slices[8] = 1.83259571\n",
    "    phi_slices[9] = 2.35619449\n",
    "    phi_slices[10] = 2.87979327\n",
    "    phi_slices[11] = -2.87979327\n",
    "    phi_slices[12] = -2.35619449\n",
    "\n",
    "    for slice in range(n_phi_slices):\n",
    "        phi_min, phi_max = phi_slices[slice], phi_slices[slice + 1]\n",
    "        if (phi >= phi_min) and (phi < phi_max):\n",
    "            return R - perform_poly_cuda(dt, slice)   \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FV: Poly\n",
    "\"\"\"\n",
    "coeffs = np.array([[-1.78880746e-13, 4.91268301e-10, -4.96134607e-07, 2.26430932e-04, -4.71792008e-02, 7.33811298e+01],\n",
    "            [-1.72264463e-13, 4.59149636e-10, -4.59325165e-07, 2.14612376e-04, -4.85599108e-02, 7.35290867e+01],\n",
    "            [-3.17099156e-14, 7.26336129e-11, -6.99495385e-08, 3.85531008e-05, -1.33386004e-02, 7.18002889e+01],\n",
    "            [-6.12280314e-14, 1.67968911e-10, -1.83625538e-07, 1.00457608e-04, -2.86728022e-02, 7.22754350e+01],\n",
    "            [-1.89897962e-14, 1.52777215e-11, -2.79681508e-09, 1.25689887e-05, -1.33093804e-02, 7.17662251e+01],\n",
    "            [-2.32118621e-14, 7.30043322e-11, -9.40606298e-08, 6.29728588e-05, -2.28150175e-02, 7.22661091e+01],\n",
    "            [-8.29749194e-14, 2.31096069e-10, -2.47867121e-07, 1.27576029e-04, -3.24702414e-02, 7.26357609e+01],\n",
    "            [-2.00718008e-13, 5.44135757e-10, -5.59484466e-07, 2.73028553e-04, -6.46879791e-02, 7.45264998e+01],\n",
    "            [-7.77420021e-14, 1.97357045e-10, -1.90016273e-07, 8.99659454e-05, -2.30169916e-02, 7.25038258e+01],\n",
    "            [-5.27296334e-14, 1.49415580e-10, -1.58205132e-07, 8.00275441e-05, -2.13559394e-02, 7.23995451e+01],\n",
    "            [-6.00198219e-14, 1.55333004e-10, -1.60367908e-07, 7.97754165e-05, -1.94435594e-02, 7.22714399e+01],\n",
    "            [-8.89919309e-14, 2.40830027e-10, -2.57060475e-07, 1.33002951e-04, -3.32969110e-02, 7.28696020e+01]])\n",
    "\n",
    "@numba.njit\n",
    "def perform_poly(dt, c):\n",
    "    poly_results = coeffs[c][0]*dt**5 + coeffs[c][1]*dt**4 + coeffs[c][2]*dt**3 + coeffs[c][3]*dt**2 + coeffs[c][4]*dt + coeffs[c][5]\n",
    "    return poly_results\n",
    "\n",
    "# copy coeffs to cuda shared memory\n",
    "cuda.to_device(coeffs)\n",
    "\n",
    "@cuda.jit\n",
    "def perform_poly_cuda(dt, c):\n",
    "\n",
    "    return (\n",
    "        coeffs[c][0] * math.pow(dt, 5) + coeffs[c][1] * math.pow(dt, 4) + coeffs[c][2] * math.pow(dt, 3) +\n",
    "        coeffs[c][3] * math.pow(dt, 2) + coeffs[c][4] * dt + coeffs[c][5]\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FV: R Wall cut based on phi position\n",
    "\"\"\"\n",
    "@numba.njit\n",
    "def fv_phi_r(x, y, dt):\n",
    "    dR_phi = calc_dR_phi(x, y, dt)\n",
    "    contour = fv_wall_contour(dt) - 3  # add cm stand-off\n",
    "    expandable = (dt > 71) & (dt < 900)\n",
    "\n",
    "    mask = ((dR_phi < contour) & expandable) | ((dR_phi < contour) & ~expandable)\n",
    "    return mask & (dR_phi <= 0)\n",
    "\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def fv_phi_r_cuda(x, y, dt):    \n",
    "    dR_phi = calc_dR_phi_cuda(x, y, dt)\n",
    "    contour = fv_wall_contour_cuda(dt) - 3 # add cm stand-off    \n",
    "    expandable = dt > 71 and dt < 900\n",
    "\n",
    "    mask = ((dR_phi < contour) and expandable) or ((dR_phi < contour) and not expandable)\n",
    "    return mask and dR_phi <= 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FV: Resistor cutout\n",
    "\"\"\"\n",
    "@numba.njit\n",
    "def fv_resistor(x, y):\n",
    "    res1X, res1Y, res1R = -69.8, 3.5, 6\n",
    "    res2X, res2Y, res2R = -67.5, -14.3, 6\n",
    "    \n",
    "    insideRes1 = (x-res1X)*(x-res1X) + (y-res1Y)*(y-res1Y) > res1R**2\n",
    "    insideRes2 = (x-res2X)*(x-res2X) + (y-res2Y)*(y-res2Y) > res2R**2\n",
    "    \n",
    "    return (insideRes1 & insideRes2)\n",
    "\n",
    "@cuda.jit\n",
    "def fv_resistor_cuda(x, y):\n",
    "    res1X, res1Y, res1R = -69.8, 3.5, 6\n",
    "    res2X, res2Y, res2R = -67.5, -14.3, 6\n",
    "\n",
    "    insideRes1 = ((x - res1X) ** 2 + (y - res1Y) ** 2) > res1R**2 \n",
    "    insideRes2 = ((x - res2X) ** 2 + (y - res2Y) ** 2) > res2R**2\n",
    "\n",
    "    return insideRes1 and insideRes2\n",
    "\n",
    "\"\"\"\n",
    "FV: Z\n",
    "\"\"\"\n",
    "@numba.njit\n",
    "def fv_z(dt):\n",
    "    return (dt > 71) & (dt < 1030)\n",
    "\n",
    "@cuda.jit\n",
    "def fv_z_cuda(dt):\n",
    "    return (dt > 71) and (dt < 1030)\n",
    "\n",
    "\"\"\"\n",
    "ROI: S1 and S2\n",
    "\"\"\"\n",
    "@numba.njit\n",
    "def roi(s1c, s2, s2c):\n",
    "    return (s1c > 3.) and (s1c < 80.) and (s2 > 14.5 * 44.5) and (s2c < 10 ** 4.5)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def roi_cuda(s1c, s2, s2c):\n",
    "    return (s1c > 3.) and (s1c < 80.) and (s2 > 14.5 * 44.5) and (s2c < 10 ** 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def process_events(ss_x, ss_y, ss_dt, ss_s1c, ss_s2, ss_s2c, mc_detS1, mc_detS2):\n",
    "    n_fv, n_roi, n_fv_roi = 0, 0, 0\n",
    "    n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi = 0, 0, 0, 0\n",
    "\n",
    "    # Loop over events\n",
    "    for i in range(len(ss_x)):\n",
    "        \n",
    "        # Evaluate cuts\n",
    "        cut_bool_resistor_fv = fv_resistor(ss_x[i], ss_y[i])\n",
    "        cut_bool_z = fv_z(ss_dt[i] / 1000)\n",
    "        cut_bool_r = fv_phi_r(ss_x[i], ss_y[i], ss_dt[i] / 1000)\n",
    "        fv_cut = cut_bool_resistor_fv and cut_bool_z and cut_bool_r\n",
    "        roi_cut = roi(ss_s1c[i], ss_s2[i], ss_s2c[i])\n",
    "\n",
    "        # Examine if MSSI\n",
    "        nS1, nS2 = 0, 0\n",
    "        for j in range(len(mc_detS1[i])):\n",
    "            if mc_detS1[i][j] > 0.:\n",
    "                nS1 += 1\n",
    "            if mc_detS2[i][j] > 0.:\n",
    "                nS2 += 1\n",
    "        is_mssi = nS1 > nS2\n",
    "        \n",
    "        # Now evaluate cuts and count events\n",
    "        if is_mssi:\n",
    "            n_mssi += 1\n",
    "        if fv_cut:\n",
    "            n_fv += 1\n",
    "            if is_mssi:\n",
    "                n_fv_mssi += 1\n",
    "            if roi_cut:\n",
    "                n_fv_roi += 1\n",
    "                if is_mssi:\n",
    "                    n_fv_roi_mssi += 1\n",
    "        if roi_cut:\n",
    "            n_roi += 1\n",
    "            if is_mssi:\n",
    "                n_roi_mssi += 1\n",
    "\n",
    "    return n_fv, n_roi, n_fv_roi, n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def process_events_cuda(ss_x, ss_y, ss_dt, ss_s1c, ss_s2, ss_s2c, mc_detS1, mc_detS2, \n",
    "                        n_fv, n_roi, n_fv_roi, n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi):\n",
    "\n",
    "    # Set thread\n",
    "    i = numba.cuda.grid(1)\n",
    "    # Don't process out of bounds\n",
    "    if i >= ss_x.shape[0]:\n",
    "        return\n",
    "\n",
    "    # Evaluate cuts\n",
    "    cut_bool_resistor_fv = fv_resistor_cuda(ss_x[i], ss_y[i])\n",
    "    cut_bool_z = fv_z_cuda(ss_dt[i] / 1000)\n",
    "    cut_bool_r = fv_phi_r_cuda(ss_x[i], ss_y[i], ss_dt[i] / 1000)\n",
    "    fv_cut = cut_bool_resistor_fv and cut_bool_z and cut_bool_r\n",
    "    roi_cut = roi_cuda(ss_s1c[i], ss_s2[i], ss_s2c[i])\n",
    "\n",
    "    # Examine if MSSI\n",
    "    nS1, nS2 = 0, 0\n",
    "    for j in range(len(mc_detS1[i])):\n",
    "        if mc_detS1[i][j] > 0.:\n",
    "            nS1 += 1\n",
    "        if mc_detS2[i][j] > 0.:\n",
    "            nS2 += 1\n",
    "    is_mssi = nS1 > nS2\n",
    "\n",
    "    # Now evaluate cuts and count events\n",
    "    if roi_cut:\n",
    "        cuda.atomic.add(n_roi, 0, 1)\n",
    "        if is_mssi:\n",
    "            cuda.atomic.add(n_roi_mssi, 0, 1)\n",
    "\n",
    "    if is_mssi:\n",
    "        cuda.atomic.add(n_mssi, 0, 1)\n",
    "    if fv_cut:\n",
    "        cuda.atomic.add(n_fv, 0, 1)\n",
    "        if is_mssi:\n",
    "            cuda.atomic.add(n_fv_mssi, 0, 1)\n",
    "        if roi_cut:\n",
    "            cuda.atomic.add(n_fv_roi, 0, 1)\n",
    "            if is_mssi:\n",
    "                cuda.atomic.add(n_fv_roi_mssi, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    component = file.split('/SS_skim_')[1][:-5]\n",
    "\n",
    "    tfile = up.open(file)\n",
    "    scatters = tfile['Scatters']\n",
    "    truth = tfile['RQMCTruth']\n",
    "\n",
    "    # Read arrays\n",
    "    ss_x = scatters['ss.x_cm'].array()\n",
    "    ss_y = scatters['ss.y_cm'].array()\n",
    "    ss_dt = scatters['ss.driftTime_ns'].array()\n",
    "    ss_s1c = scatters['ss.correctedS1Area_phd'].array()\n",
    "    ss_s2 = scatters['ss.s2Area_phd'].array()\n",
    "    ss_s2c = scatters['ss.correctedS2Area_phd'].array()\n",
    "\n",
    "    mc_detS1 = truth['mcTruthVertices.detectedS1Photons'].array()\n",
    "    mc_detS2 = truth['mcTruthVertices.detectedS2Photons'].array()\n",
    "\n",
    "    n_events = len(ss_x)\n",
    "\n",
    "    result = process_events(ss_x, ss_y, ss_dt, ss_s1c, ss_s2, ss_s2c, mc_detS1, mc_detS2)\n",
    "    n_fv, n_roi, n_fv_roi, n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi = result\n",
    "\n",
    "    event_weight = 1e-6 / 200\n",
    "\n",
    "    return component, n_events, n_fv, n_roi, n_fv_roi, n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi, event_weight\n",
    "\n",
    "def process_file_cuda(file):\n",
    "    component = file.split('/SS_skim_')[1][:-5]\n",
    "\n",
    "    tfile = up.open(file)\n",
    "    scatters = tfile['Scatters']\n",
    "    truth = tfile['RQMCTruth']\n",
    "\n",
    "    # Read arrays and copy to GPU\n",
    "    ss_x = cuda.to_device(scatters['ss.x_cm'].array())\n",
    "    ss_y = cuda.to_device(scatters['ss.y_cm'].array())\n",
    "    ss_dt = cuda.to_device(scatters['ss.driftTime_ns'].array())\n",
    "    ss_s1c = cuda.to_device(scatters['ss.correctedS1Area_phd'].array())\n",
    "    ss_s2 = cuda.to_device(scatters['ss.s2Area_phd'].array())\n",
    "    ss_s2c = cuda.to_device(scatters['ss.correctedS2Area_phd'].array())\n",
    "\n",
    "    # Need to zero pad jagged arrays\n",
    "    det_s1 = truth['mcTruthVertices.detectedS1Photons'].array()\n",
    "    det_s2 = truth['mcTruthVertices.detectedS2Photons'].array()\n",
    "    pad_size = ak.max(ak.num(det_s1))\n",
    "    mc_detS1 = cuda.to_device(ak.fill_none(ak.pad_none(det_s1, pad_size), 0))\n",
    "    mc_detS2 = cuda.to_device(ak.fill_none(ak.pad_none(det_s2, pad_size), 0))\n",
    "\n",
    "    # Result counters\n",
    "    n_fv = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    n_roi = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    n_fv_roi = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    n_mssi = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "    n_fv_mssi = cuda.to_device(np.zeros(1, dtype=np.int32)) \n",
    "    n_roi_mssi = cuda.to_device(np.zeros(1, dtype=np.int32)) \n",
    "    n_fv_roi_mssi = cuda.to_device(np.zeros(1, dtype=np.int32))\n",
    "\n",
    "    # Launch kernel\n",
    "    n_events = len(scatters['ss.x_cm'].array())\n",
    "    block_size = 256\n",
    "    n_blocks = (n_events + block_size - 1) // block_size\n",
    "\n",
    "    process_events_cuda[n_blocks, block_size](ss_x, ss_y, ss_dt, ss_s1c, ss_s2, ss_s2c, mc_detS1, mc_detS2,\n",
    "                                              n_fv, n_roi, n_fv_roi, n_mssi, n_fv_mssi, n_roi_mssi, n_fv_roi_mssi)\n",
    "\n",
    "    # Copy result back\n",
    "    cuda.synchronize()\n",
    "    n_fv_host = n_fv.copy_to_host()[0]\n",
    "    n_roi_host = n_roi.copy_to_host()[0]\n",
    "    n_fv_roi_host = n_fv_roi.copy_to_host()[0]\n",
    "    n_mssi_host = n_mssi.copy_to_host()[0]\n",
    "    n_fv_mssi_host = n_fv_mssi.copy_to_host()[0]\n",
    "    n_roi_mssi_host = n_roi_mssi.copy_to_host()[0]\n",
    "    n_fv_roi_mssi_host = n_fv_roi_mssi.copy_to_host()[0]\n",
    "\n",
    "    event_weight = 1e-6 / 200\n",
    "\n",
    "    return component, n_events, n_fv_host, n_roi_host, n_fv_roi_host, n_mssi_host, n_fv_mssi_host, n_roi_mssi_host, n_fv_roi_mssi_host, event_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the files to be used. \n",
    "In this example, the files are stored locally under `/shared/scratch/ak18773/lz/mssi/`. \n",
    "Each file is a ROOT file containing the output of an `LZLAMA` simulation (the `NEST` handler); more details can be found in [arvix:2001.09363](https://arxiv.org/abs/2001.09363)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/shared/scratch/ak18773/lz/mssi/*.root\")\n",
    "print(f'N. files: {len(files)}')\n",
    "files = files[:6]\n",
    "print(f'N. files to process: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_results = [dask.delayed(process_file)(file) for file in files]\n",
    "futures = client.compute(delayed_results)\n",
    "\n",
    "# monitor the progress\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once complete, retrieve the results\n",
    "results = client.gather(futures)\n",
    "results_df = pd.DataFrame(results, columns=['Source', 'nSS', 'nSS FV', 'nSS ROI', 'nSS FV ROI', 'nMSSI', 'nMSSI FV', 'nMSSI ROI', 'nMSSI FV ROI', 'eventWeight'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_results = [dask.delayed(process_file_cuda)(file) for file in files]\n",
    "futures = client.compute(delayed_results)\n",
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.gather(futures)\n",
    "results_df_cuda = pd.DataFrame(results, columns=['Source', 'nSS', 'nSS FV', 'nSS ROI', 'nSS FV ROI', 'nMSSI', 'nMSSI FV', 'nMSSI ROI', 'nMSSI FV ROI', 'eventWeight'])\n",
    "results_df_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing\n",
    "Now that we have the fraction of events in each region, we can calculate the rates using the known `decays/day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = {\n",
    "    \"Co60_CalibrationSourceTubes\": 4690.57902,\n",
    "    \"Co60_DomePMTs\": 3885.410702,\n",
    "    \"K40_BottomTruss\": 28927.99798,\n",
    "    \"K40_DomePMTs\": 88935.50817,\n",
    "    \"Th232-early_BottomTPCPMTBodies\": 38003.65201,\n",
    "    \"Th232-late_BottomTPCPMTBases\": 20626.61384,\n",
    "    \"Th232-late_BottomTPCPMTBodies\": 51716.2229,\n",
    "    \"Th232-late_ForwardFieldResistors\": 77545.76613,\n",
    "    \"Th232-late_HVInnerCone\": 363483.6619,\n",
    "    \"U238-late_AnodeGridWires\": 4316.423461\n",
    "}\n",
    "rates_df = pd.DataFrame(list(rates.items()), columns=[\"Source\", \"Rate (Decays/day)\"])\n",
    "rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match up where 'Source' is the same in both dataframes, and combine them\n",
    "df = pd.merge(results_df, rates_df, on='Source')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SS/day'] =  df['nSS'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['SS/day FV'] = df['nSS FV'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['SS/day ROI'] = df['nSS ROI'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['SS/day FV ROI'] = df['nSS FV ROI'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['MSSI/day'] = df['nMSSI'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['MSSI/day FV'] = df['nMSSI FV'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['MSSI/day ROI'] = df['nMSSI ROI'] * df['eventWeight'] * df['Rate (Decays/day)']\n",
    "df['MSSI/day FV ROI'] = df['nMSSI FV ROI'] * df['eventWeight'] * df['Rate (Decays/day)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of events per day from each source\n",
    "print('Number of SS events expected per day')\n",
    "all = df['SS/day'].sum()\n",
    "in_fv = df['SS/day FV'].sum()\n",
    "in_roi = df['SS/day ROI'].sum()\n",
    "in_fv_roi = df['SS/day FV ROI'].sum()\n",
    "print(f'N. SS / day:   {all}')\n",
    "print(f'In FV / day:     {in_fv}')\n",
    "print(f'In ROI / day:     {in_roi}')\n",
    "print(f'N. FV ROI / day: {in_fv_roi}')\n",
    "print('----------------------------')\n",
    "print('Number of MSSI events expected per day')\n",
    "all = df['MSSI/day'].sum()\n",
    "in_fv = df['MSSI/day FV'].sum()\n",
    "in_roi = df['MSSI/day ROI'].sum()\n",
    "in_fv_roi = df['MSSI/day FV ROI'].sum()\n",
    "in_dataset = in_fv_roi * 220\n",
    "print(f'N. MSSI / day:   {all}')\n",
    "print(f'In FV / day:     {in_fv}')\n",
    "print(f'In ROI / day:     {in_roi}')\n",
    "print(f'N. FV ROI / day: {in_fv_roi}')\n",
    "print('----------------------------')\n",
    "print('Fraction of SS events that are MSSI')\n",
    "fraction = df['MSSI/day FV ROI'].sum() / df['SS/day FV ROI'].sum()\n",
    "print(f'fraction: {fraction:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does processing time compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On GPU00...\n",
    "* 14.6s # numba.njit\n",
    "* 45+mins # regular Python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
